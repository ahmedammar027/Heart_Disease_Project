{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb24440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix , root_mean_squared_error, mean_squared_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8091a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/new_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab17172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = df.copy()\n",
    "df_bin['target_bin'] = (df_bin['num'] != 0).astype(int)  # 0 -> 0, else -> 1\n",
    "\n",
    "X = df_bin.drop(columns=['num','target_bin'], axis=1)\n",
    "y = df_bin['target_bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1b2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Function to print training and testing results\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train == False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e12fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    329.0  407.0       1.0      736.0         736.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[329   0]\n",
      " [  0 407]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 78.26%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.791667    0.776786  0.782609    0.784226      0.783417\n",
      "recall      0.695122    0.852941  0.782609    0.774032      0.782609\n",
      "f1-score    0.740260    0.813084  0.782609    0.776672      0.780630\n",
      "support    82.000000  102.000000  0.782609  184.000000    184.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[57 25]\n",
      " [15 87]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with a random state for reproducibility\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print training and testing scores\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5079d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
      "Best paramters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 15, 'min_samples_split': 2, 'splitter': 'best'})\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 83.42%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.826498    0.840095  0.834239    0.833297      0.834017\n",
      "recall       0.796353    0.864865  0.834239    0.830609      0.834239\n",
      "f1-score     0.811146    0.852300  0.834239    0.831723      0.833904\n",
      "support    329.000000  407.000000  0.834239  736.000000    736.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[262  67]\n",
      " [ 55 352]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 84.78%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.864865    0.836364  0.847826    0.850614      0.849065\n",
      "recall      0.780488    0.901961  0.847826    0.841224      0.847826\n",
      "f1-score    0.820513    0.867925  0.847826    0.844219      0.846795\n",
      "support    82.000000  102.000000  0.847826  184.000000    184.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[64 18]\n",
      " [10 92]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters and their respective ranges\n",
    "params = {\n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"splitter\":(\"best\", \"random\"), \n",
    "    \"max_depth\":(list(range(1, 20))), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "# Initialize the model with a random state for reproducibility\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "# Train the model\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "# Apply the best parameters and re-train the model\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Print scores after hyperparameter tuning\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b997fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best paramters: {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 70, 'bootstrap': False})\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 95.24%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.962264    0.944976  0.952446    0.953620      0.952704\n",
      "recall       0.930091    0.970516  0.952446    0.950304      0.952446\n",
      "f1-score     0.945904    0.957576  0.952446    0.951740      0.952358\n",
      "support    329.000000  407.000000  0.952446  736.000000    736.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[306  23]\n",
      " [ 12 395]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 84.24%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1  accuracy   macro avg  weighted avg\n",
      "precision   0.844156    0.841121  0.842391    0.842639      0.842474\n",
      "recall      0.792683    0.882353  0.842391    0.837518      0.842391\n",
      "f1-score    0.817610    0.861244  0.842391    0.839427      0.841798\n",
      "support    82.000000  102.000000  0.842391  184.000000    184.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[65 17]\n",
      " [12 90]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the range of hyperparameters to search over\n",
    "# Number of trees\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# Maximum depth of the trees\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum samples needed to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum samples needed at a leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Whether bootstrap samples are used\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Combine into a hyperparameter grid\n",
    "random_grid = {'n_estimators': n_estimators, \n",
    "               'max_depth': max_depth, \n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, \n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Instantiate the model\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search\n",
    "rf_cv = RandomizedSearchCV(estimator=rf_clf, \n",
    "                           scoring='f1', \n",
    "                           param_distributions=random_grid,\n",
    "                           n_iter=100, \n",
    "                           cv=3, \n",
    "                           verbose=2, \n",
    "                           random_state=42, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")\n",
    "\n",
    "# Train the Random Forest with the best parameters\n",
    "rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model with tuned hyperparameters\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4e20da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# حفظ الموديل\n",
    "joblib.dump(rf_clf, '../models/hierarchical_model.pkl')\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3bb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
